{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Fundus Image Analysis for Early Detection of Diabetic Retinopathy\n",
    "## Training Xception Model\n",
    "\n",
    "This notebook trains a deep learning model using Xception architecture for classifying diabetic retinopathy severity levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Training and Testing Path\n",
    "\n",
    "Assign variables for train and test paths. The Xception model requires input images of size 299x299."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing Path Configuration\n",
    "TRAIN_PATH = '../data'\n",
    "TEST_PATH = '../data'\n",
    "\n",
    "# Xception Model Configuration\n",
    "IMG_SIZE = 299  # Xception input size is 299x299\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "print(f\"Training Path: {TRAIN_PATH}\")\n",
    "print(f\"Testing Path: {TEST_PATH}\")\n",
    "print(f\"Image Size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Number of Classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for building and training the deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure ImageDataGenerator Class\n",
    "\n",
    "ImageDataGenerator is used for data augmentation. We apply various transformations to increase dataset diversity:\n",
    "- Image shifts (width_shift_range, height_shift_range)\n",
    "- Image flips (horizontal_flip, vertical_flip)\n",
    "- Image rotations (rotation_range)\n",
    "- Image brightness (brightness_range)\n",
    "- Image zoom (zoom_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,                    # Normalize pixel values to [0,1]\n",
    "    rotation_range=20,                 # Image rotations (0-20 degrees)\n",
    "    width_shift_range=0.2,             # Image shifts horizontally (20%)\n",
    "    height_shift_range=0.2,            # Image shifts vertically (20%)\n",
    "    horizontal_flip=True,              # Image flips horizontally\n",
    "    vertical_flip=True,                # Image flips vertically\n",
    "    zoom_range=0.2,                    # Image zoom (20%)\n",
    "    shear_range=0.2,                   # Shear transformation\n",
    "    brightness_range=[0.8, 1.2],       # Image brightness adjustment\n",
    "    fill_mode='nearest',               # Fill mode for new pixels\n",
    "    validation_split=0.2               # 20% for validation\n",
    ")\n",
    "\n",
    "# Testing Data - Only Rescaling (No Augmentation)\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "print(\"Data Augmentation Configured Successfully!\")\n",
    "print(\"Training augmentation includes: rotation, shift, flip, zoom, shear, brightness\")\n",
    "print(\"Testing data: only rescaling applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Apply ImageDataGenerator to Train and Test Sets\n",
    "\n",
    "Use flow_from_directory() to load images from subdirectories.\n",
    "\n",
    "**Arguments:**\n",
    "- directory: Path where data is located\n",
    "- target_size: Size to resize images (299x299 for Xception)\n",
    "- batch_size: Number of images per batch (64)\n",
    "- class_mode: 'categorical' for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=TRAIN_PATH,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Validation/Test Set\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=TEST_PATH,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nClass Indices: {train_generator.class_indices}\")\n",
    "print(f\"Training Samples: {train_generator.samples}\")\n",
    "print(f\"Validation Samples: {test_generator.samples}\")\n",
    "print(f\"Steps per Epoch: {train_generator.samples // BATCH_SIZE}\")\n",
    "print(f\"Validation Steps: {test_generator.samples // BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Pre-trained CNN Model as Feature Extractor\n",
    "\n",
    "Load Xception model pre-trained on ImageNet as a feature extractor.\n",
    "- include_top=False: Exclude fully connected layers\n",
    "- weights='imagenet': Use pre-trained weights\n",
    "- Freeze all convolution blocks to prevent weight updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Xception Pre-trained Model\n",
    "base_model = Xception(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers in base model (Feature Extraction)\n",
    "base_model.trainable = False\n",
    "\n",
    "print(f\"Base Model: Xception\")\n",
    "print(f\"Input Shape: {IMG_SIZE}x{IMG_SIZE}x3\")\n",
    "print(f\"Pre-trained Weights: ImageNet\")\n",
    "print(f\"Include Top: False (using as feature extractor)\")\n",
    "print(f\"Trainable: False (all layers frozen)\")\n",
    "print(f\"Total Base Model Layers: {len(base_model.layers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Adding Dense Layers\n",
    "\n",
    "Add custom dense layers on top of the Xception base model.\n",
    "The output layer has neurons equal to the number of classes (5) with softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Custom Classification Layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D(name='global_avg_pooling')(x)\n",
    "x = Dense(512, activation='relu', name='dense_512')(x)\n",
    "x = Dropout(0.5, name='dropout_1')(x)\n",
    "x = Dense(256, activation='relu', name='dense_256')(x)\n",
    "x = Dropout(0.3, name='dropout_2')(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax', name='output')(x)\n",
    "\n",
    "# Create Final Model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "print(\"Custom Layers Added:\")\n",
    "print(\"  1. GlobalAveragePooling2D\")\n",
    "print(\"  2. Dense(512, activation='relu')\")\n",
    "print(\"  3. Dropout(0.5)\")\n",
    "print(\"  4. Dense(256, activation='relu')\")\n",
    "print(\"  5. Dropout(0.3)\")\n",
    "print(f\"  6. Dense({NUM_CLASSES}, activation='softmax') - Output Layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Model Summary\n",
    "\n",
    "Display the complete model architecture with layer details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Configure the Learning Process\n",
    "\n",
    "Compile the model with:\n",
    "- Optimizer: Adam (adaptive learning rate)\n",
    "- Loss Function: categorical_crossentropy (for multi-class classification)\n",
    "- Metrics: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model Compiled Successfully!\")\n",
    "print(\"  - Optimizer: Adam (learning_rate=0.0001)\")\n",
    "print(\"  - Loss Function: categorical_crossentropy\")\n",
    "print(\"  - Metrics: accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Setup Callbacks\n",
    "\n",
    "Configure callbacks for training:\n",
    "- ModelCheckpoint: Save best model based on validation loss\n",
    "- EarlyStopping: Stop training if no improvement\n",
    "- ReduceLROnPlateau: Reduce learning rate when metric plateaus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint: Save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'Updated-Xception-diabetic-retinopathy.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# EarlyStopping: Stop if no improvement\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau: Reduce learning rate\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, early_stop, reduce_lr]\n",
    "\n",
    "print(\"Callbacks Configured:\")\n",
    "print(\"  1. ModelCheckpoint - Save best model\")\n",
    "print(\"  2. EarlyStopping - Stop if no improvement for 5 epochs\")\n",
    "print(\"  3. ReduceLROnPlateau - Reduce LR by 0.5 if plateau for 3 epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Train the Model\n",
    "\n",
    "Train the model using fit() method.\n",
    "\n",
    "**Arguments:**\n",
    "- steps_per_epoch: Total training samples / batch_size\n",
    "- epochs: Number of training iterations\n",
    "- validation_data: Test generator for validation\n",
    "- validation_steps: Total validation samples / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate steps\n",
    "steps_per_epoch = train_generator.samples // BATCH_SIZE\n",
    "validation_steps = test_generator.samples // BATCH_SIZE\n",
    "\n",
    "print(f\"Training Configuration:\")\n",
    "print(f\"  - Steps per Epoch: {steps_per_epoch}\")\n",
    "print(f\"  - Validation Steps: {validation_steps}\")\n",
    "print(f\"  - Total Epochs: {EPOCHS}\")\n",
    "print(f\"\\nStarting Training...\\n\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Save the Model\n",
    "\n",
    "Save the trained model in HDF5 (.h5) format.\n",
    "H5 file contains multidimensional arrays of scientific data including model architecture and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model_path = 'Updated-Xception-diabetic-retinopathy.h5'\n",
    "model.save(model_path)\n",
    "\n",
    "print(f\"Model saved successfully to: {model_path}\")\n",
    "print(f\"Model file format: HDF5 (.h5)\")\n",
    "print(f\"File contains: Architecture + Weights + Optimizer state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Evaluate the Model\n",
    "\n",
    "Evaluate the trained model on the test set and display performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=validation_steps)\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"  - Test Loss: {test_loss:.4f}\")\n",
    "print(f\"  - Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Training history summary\n",
    "print(f\"\\nTraining History:\")\n",
    "print(f\"  - Final Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"  - Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"  - Final Validation Loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "print(f\"  - Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"  - Best Validation Loss: {min(history.history['val_loss']):.4f}\")\n",
    "print(f\"  - Best Validation Accuracy: {max(history.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
